{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import scipy.optimize as optimize\n",
    "import scipy.stats as stats\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "# Datasets\n",
    "\n",
    "folder_path = r\"C:\\Users\\Alicia BASSIERE\\OneDrive - GENES\\Documents\\Paper 01 - DIPU\\Estimation\\wind\\clusterOnshore\"\n",
    "file_prefix = \"cluster_\"\n",
    "\n",
    "csv_files = [file for file in os.listdir(folder_path) if file.startswith(file_prefix)]\n",
    "dataframes = []\n",
    "zero_count = 0\n",
    "\n",
    "for file in csv_files:\n",
    "    file_path = os.path.join(folder_path, file)\n",
    "    data = pd.read_csv(file_path, index_col=0)\n",
    "    data.drop(data.tail(1).index, inplace=True)\n",
    "\n",
    "    # Remove zeros from the dataframe\n",
    "    data = data[data != 0]\n",
    "\n",
    "    # Count the number of zeros removed\n",
    "    zero_count += (data == 0).sum().sum()\n",
    "\n",
    "    dataframes.append(data)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "def neg_log_likelihood(params, data):\n",
    "    alpha, beta = params\n",
    "    return -np.sum(stats.beta.logpdf(data, alpha, beta))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Dataset     Alpha      Beta\n",
      "0    Dataset_0  1.033401  2.781667\n",
      "1    Dataset_1  0.100000  0.100000\n",
      "2    Dataset_2  0.995456  3.884933\n",
      "3    Dataset_3  0.100000  0.100000\n",
      "4    Dataset_4  0.100000  0.100000\n",
      "5    Dataset_5  0.100000  0.100000\n",
      "6    Dataset_6  1.003867  3.867980\n",
      "7    Dataset_7  0.100000  0.100000\n",
      "8    Dataset_8  0.100000  0.100000\n",
      "9    Dataset_9  0.100000  0.100000\n",
      "10  Dataset_10  1.044452  1.488646\n",
      "11  Dataset_11  0.100000  0.100000\n",
      "12  Dataset_12  0.100000  0.100000\n",
      "13  Dataset_13  0.100000  0.100000\n",
      "14  Dataset_14  0.100000  0.100000\n",
      "15  Dataset_15  0.100000  0.100000\n",
      "16  Dataset_16  0.100000  0.100000\n",
      "17  Dataset_17  0.100000  0.100000\n",
      "18  Dataset_18  0.100000  0.100000\n",
      "19  Dataset_19  1.019030  1.575608\n",
      "20  Dataset_20  0.100000  0.100000\n",
      "21  Dataset_21  0.100000  0.100000\n",
      "22  Dataset_22  0.100000  0.100000\n",
      "23  Dataset_23  0.100000  0.100000\n",
      "24  Dataset_24  1.074297  3.057369\n",
      "25  Dataset_25  1.000197  5.523226\n",
      "26  Dataset_26  0.100000  0.100000\n",
      "27  Dataset_27  1.076527  3.131410\n",
      "28  Dataset_28  0.100000  0.100000\n",
      "29  Dataset_29  0.100000  0.100000\n",
      "30  Dataset_30  0.100000  0.100000\n",
      "31  Dataset_31  0.100000  0.100000\n",
      "32  Dataset_32  0.100000  0.100000\n",
      "33  Dataset_33  1.010605  4.209270\n",
      "34  Dataset_34  1.037811  3.295634\n",
      "35  Dataset_35  1.037808  3.287087\n",
      "36  Dataset_36  0.100000  0.100000\n",
      "37  Dataset_37  0.100000  0.100000\n",
      "38  Dataset_38  0.100000  0.100000\n",
      "39  Dataset_39  1.042872  4.524134\n",
      "40  Dataset_40  0.100000  0.100000\n",
      "41  Dataset_41  0.100000  0.100000\n",
      "42  Dataset_42  0.100000  0.100000\n",
      "43  Dataset_43  0.100000  0.100000\n",
      "44  Dataset_44  1.005134  4.859697\n",
      "45  Dataset_45  0.100000  0.100000\n",
      "46  Dataset_46  0.100000  0.100000\n",
      "47  Dataset_47  1.004443  4.177073\n",
      "48  Dataset_48  0.100000  0.100000\n",
      "49  Dataset_49  0.100000  0.100000\n"
     ]
    }
   ],
   "source": [
    "# Create an empty dataframe to store the results\n",
    "result_df = pd.DataFrame(columns=['Dataset', 'Alpha', 'Beta'])\n",
    "\n",
    "# Iterate over each dataframe\n",
    "for idx, data in enumerate(dataframes):\n",
    "    # Minimization\n",
    "    bounds = [(0.01, 100), (0.01, 100)] # set bounds for alpha and beta\n",
    "    result = optimize.minimize(neg_log_likelihood, [0.1, 0.1], args=(data,), bounds=bounds)\n",
    "    alpha_mle, beta_mle = result.x\n",
    "\n",
    "    # Create a temporary dataframe with the results\n",
    "    temp_df = pd.DataFrame({'Dataset': [f'Dataset_{idx}'], 'Alpha': [alpha_mle], 'Beta': [beta_mle]})\n",
    "\n",
    "    # Concatenate the temporary dataframe with the result dataframe\n",
    "    result_df = pd.concat([result_df, temp_df], ignore_index=True)\n",
    "\n",
    "\n",
    "# Print the final dataframe\n",
    "print(result_df)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Dataset      Alpha       Beta\n",
      "0    Dataset_0   1.033403   2.781675\n",
      "1    Dataset_1  45.722017  96.446003\n",
      "2    Dataset_2   0.995456   3.884933\n",
      "3    Dataset_3   5.336834  20.507501\n",
      "4    Dataset_4   9.526821  11.295595\n",
      "5    Dataset_5  23.125070  64.143078\n",
      "6    Dataset_6   1.003867   3.867979\n",
      "7    Dataset_7  68.797991  57.017934\n",
      "8    Dataset_8  44.574042  97.569084\n",
      "9    Dataset_9  22.359783  38.607490\n",
      "10  Dataset_10   1.044451   1.488645\n",
      "11  Dataset_11  60.650355  18.945196\n",
      "12  Dataset_12  76.715590  39.675659\n",
      "13  Dataset_13  85.818157  42.532584\n",
      "14  Dataset_14  36.783022  91.914761\n",
      "15  Dataset_15  79.516837  10.144954\n",
      "16  Dataset_16  15.499649  35.024739\n",
      "17  Dataset_17  38.477778  71.577363\n",
      "18  Dataset_18  75.193557  34.212173\n",
      "19  Dataset_19   1.019030   1.575609\n",
      "20  Dataset_20  77.539741  78.136129\n",
      "21  Dataset_21  11.558684  51.142564\n",
      "22  Dataset_22  87.145351  74.306470\n",
      "23  Dataset_23  57.138273  15.685532\n",
      "24  Dataset_24   1.074297   3.057367\n",
      "25  Dataset_25   1.000197   5.523224\n",
      "26  Dataset_26  79.982017  20.090480\n",
      "27  Dataset_27   1.076527   3.131409\n",
      "28  Dataset_28  64.982056  16.216716\n",
      "29  Dataset_29  74.898206  60.157402\n",
      "30  Dataset_30  12.661406  62.706534\n",
      "31  Dataset_31  72.663432  89.455459\n",
      "32  Dataset_32  98.334044  41.689483\n",
      "33  Dataset_33   1.010604   4.209263\n",
      "34  Dataset_34   1.037811   3.295639\n",
      "35  Dataset_35   1.037806   3.287081\n",
      "36  Dataset_36  39.416380  75.928035\n",
      "37  Dataset_37   0.497016  16.480077\n",
      "38  Dataset_38  72.503627  35.676546\n",
      "39  Dataset_39   1.042865   4.524151\n",
      "40  Dataset_40  74.837827  52.842885\n",
      "41  Dataset_41  86.575105  92.956308\n",
      "42  Dataset_42  67.814876  62.743082\n",
      "43  Dataset_43  27.404542  13.525436\n",
      "44  Dataset_44   1.005134   4.859699\n",
      "45  Dataset_45  61.798093  50.080515\n",
      "46  Dataset_46  16.217299  56.950710\n",
      "47  Dataset_47   1.004423   4.176974\n",
      "48  Dataset_48   0.887737  12.237534\n",
      "49  Dataset_49  15.069826  47.736031\n"
     ]
    }
   ],
   "source": [
    "# Create an empty dataframe to store the results\n",
    "result_df = pd.DataFrame(columns=['Dataset', 'Alpha', 'Beta'])\n",
    "\n",
    "# Define the folder path to save the PDF files\n",
    "save_folder = r\"C:\\Users\\Alicia BASSIERE\\OneDrive - GENES\\Documents\\Paper 02 - Mean Field\\Estimation\\Wind capacity factor\"\n",
    "\n",
    "# Iterate over each dataframe\n",
    "for idx, data in enumerate(dataframes):\n",
    "    # Remove zeros from the dataframe\n",
    "    data = data[data != 0]\n",
    "\n",
    "    # Define the bounds for alpha and beta\n",
    "    bounds = [(0.01, 100), (0.01, 100)]\n",
    "\n",
    "    # Perform differential evolution\n",
    "    result = optimize.differential_evolution(neg_log_likelihood, bounds, args=(data,))\n",
    "    alpha_mle, beta_mle = result.x\n",
    "\n",
    "    # Create a temporary dataframe with the results\n",
    "    temp_df = pd.DataFrame({'Dataset': [f'Dataset_{idx}'], 'Alpha': [alpha_mle], 'Beta': [beta_mle]})\n",
    "\n",
    "    # Concatenate the temporary dataframe with the result dataframe\n",
    "    result_df = pd.concat([result_df, temp_df], ignore_index=True)\n",
    "\n",
    "    # Plot the estimated distribution\n",
    "    x = np.linspace(0, 1, 1000)\n",
    "    y = stats.beta.pdf(x, alpha_mle, beta_mle)\n",
    "\n",
    "    plt.plot(x, y)\n",
    "    plt.xlabel('Value')\n",
    "    plt.ylabel('Density')\n",
    "    plt.title(f'Dataset_{idx} - Estimated Distribution')\n",
    "    plt.savefig(f'{save_folder}/Dataset_{idx}_distribution.pdf')\n",
    "    plt.close()\n",
    "\n",
    "# Print the final dataframe\n",
    "print(result_df)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}